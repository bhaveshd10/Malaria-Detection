# -*- coding: utf-8 -*-
"""alexnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g-KhgKEJAPKa_G5KN7KpbHoXCAHq0e38
"""

!pip install kaggle

from google.colab import drive
drive.mount('/content/gdrive')

from google.colab import files

upload = files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

import os
os.chdir('gdrive/My Drive/kaggle/malaria')
!unzip cell-images-for-detecting-malaria.zip

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models

# Transform images
_image_size = 220
_mean = [0.5, 0.5, 0.5]
_std = [0.5, 0.5, 0.5]

# Training image transform
train_trans = transforms.Compose([
    transforms.Resize(256),  
    transforms.RandomCrop(_image_size),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(.3, .3, .3),
    transforms.ToTensor(),
    transforms.Normalize(_mean, _std),
])
# Testing image transform
val_trans = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(_image_size),
    transforms.ToTensor(),
    transforms.Normalize(_mean, _std),
])

from torchvision.datasets.folder import ImageFolder, default_loader
data = ImageFolder('/content/gdrive/My Drive/kaggle/malaria/cell_images/', transform=train_trans)

train_size = int(0.9 * len(data)) # 0.9 is ratio for training
test_size = len(data) - train_size

train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])
len(train_dataset),len(test_dataset)

classes=('Parasitized','Uninfected')

batch_size = 20
train_dl = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4,)

val_dl = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4,)

import torch.nn as nn
import torch.utils.model_zoo as model_zoo

__all__ = ['AlexNet', 'alexnet']

model_urls = {
    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',
}

class AlexNet(nn.Module):

    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(64, 192, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = x.view(x.size(0), 256 * 6 * 6)
        x = self.classifier(x)
        return x


def alexnet(pretrained=False, **kwargs):
    model = AlexNet(**kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['alexnet']))
    return model

# pretrained alexnet model
model = alexnet(pretrained = True)

for param in model.parameters():
    param.requires_grad = True

n_classes = 2    

model.fc = nn.Linear(2048, n_classes)
device = torch.device("cuda:0" if torch.cuda.is_available() else 'cpu' )

model.to(device)

# Hyperparameter definition
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(
    model.parameters(),
    lr=0.0001,
)
# Number of Epochs
epochs = 20

# Training
loss_graph1 =[]
for epoch in range(epochs):
    print(f"Epoch {epoch+1}/{epochs}")

    running_loss, correct = 0.0, 0
    for X, y in train_dl:
        X, y = X.to(device), y.to(device)
        
        optimizer.zero_grad()
        y_ = model(X)
        loss = criterion(y_, y)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        
        # Statistics
        print(f"    batch loss: {loss.item():0.3f}")
        _, y_label_ = torch.max(y_, 1)
        correct += (y_label_ == y).sum().item()
        running_loss += loss.item() * X.shape[0]
    
    print(f"  Train Loss: {running_loss / len(train_dl.dataset)}")
    lossy = running_loss / len(train_dl.dataset)
    loss_graph1.append(lossy)
    print(f"  Train Acc:  {correct / len(train_dl.dataset)}")

plt.plot(loss_graph1)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

# Testing
loss_graph2=[]
for epoch in range(epochs):
    print(f"Epoch {epoch}/{epoch}")
    
    # Eval
    model.eval()
    
    running_loss, correct = 0.0, 0
    with torch.no_grad():
        for X, y in val_dl:
            X, y = X.to(device), y.to(device)            
                               
            y_ = model(X)
        
            # Statistics
            _, y_label_ = torch.max(y_, 1)
            correct += (y_label_ == y).sum().item()
            loss = criterion(y_, y)
            running_loss += loss.item() * X.shape[0]
            
    
    print(f"  Valid Loss: {running_loss / len(val_dl.dataset)}")
    print(f"  Valid Acc:  {correct / len(val_dl.dataset)}")
    loss_test = running_loss / len(val_dl.dataset)
    loss_graph2.append(loss_test)
    print()

def imshow(img):
  img = img / 2 + 0.5     # unnormalize
  npimg = img.numpy() # converts image into numpy
  plt.imshow(np.transpose(npimg, (1, 2, 0)))
  plt.show()

def im_convert(tensor):
  image = tensor.cpu().clone().numpy()
  image = image.transpose(1, 2, 0)
  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))
  image = image.clip(0, 1)
  return image

# Display Result
dataiter = iter(val_dl)
 
images, labels = dataiter.next()
 
images = images.to(device)
 
labels = labels.to(device)
 
output = model(images)
 
_, preds = torch.max(output, 1)
 
fig = plt.figure(figsize=(30, 5))
 
for idx in np.arange(20):
 
  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
 
  plt.imshow(im_convert(images[idx]))
 
  ax.set_title("{} ({})".format(str(classes[preds[idx].item()]), str(classes[labels[idx].item()])), color=("green" if preds[idx]==labels[idx] else "red"))