# -*- coding: utf-8 -*-
"""resnet50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1snRgMhThxaTWw8cWBxEse-tDoNmx01Tc
"""

!pip install kaggle

from google.colab import drive
drive.mount('/content/gdrive')

from google.colab import files

upload = files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria -p /content/gdrive/My\ Drive/kaggle/malaria

import os
os.chdir('gdrive/My Drive/kaggle/malaria')
!unzip cell-images-for-detecting-malaria.zip

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import models

# Transform image
_image_size = 220
_mean = [0.5, 0.5, 0.5]
_std = [0.5, 0.5, 0.5]

train_trans = transforms.Compose([
    transforms.Resize(256),  
    transforms.RandomCrop(_image_size),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(.3, .3, .3),
    transforms.ToTensor(),
    transforms.Normalize(_mean, _std),
])
val_trans = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(_image_size),
    transforms.ToTensor(),
    transforms.Normalize(_mean, _std),
])

from torchvision.datasets.folder import ImageFolder, default_loader
data = ImageFolder('/content/gdrive/My Drive/kaggle/malaria/cell_images/', transform=train_trans)

# Traing-Test ratio 90-10
train_size = int(0.9 * len(data)) # 0.9 is ratio for training
test_size = len(data) - train_size

data.imgs

train_dataset, test_dataset = torch.utils.data.random_split(data, [train_size, test_size])
len(train_dataset),len(test_dataset)

classes=('Parasitized','Uninfected')

batch_size = 20
# Load Train and Test Data
train_dl = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4,)

val_dl = DataLoader(test_dataset,batch_size=batch_size,shuffle=False,num_workers=4,)

# Pretrained resnet50 model
model = models.resnet50(pretrained=True)

for param in model.parameters():
    param.requires_grad = True

n_classes = 2    

model.fc = nn.Linear(2048, n_classes)
device = torch.device("cuda:0" if torch.cuda.is_available() else 'cpu' )

model.to(device)

# Defining Hyperparameters
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adagrad(
    model.parameters(),
    lr=0.0001,
)

# Number of Epochs
epochs = 20

loss_graph1 =[]
loss_graph2= []
# Training
for epoch in range(epochs):
    print(f"Epoch {epoch+1}/{epochs}")

    running_loss, correct = 0.0, 0
    for X, y in train_dl:
        X, y = X.to(device), y.to(device)
        
        optimizer.zero_grad()
        
        y_ = model(X)
        loss = criterion(y_, y)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        
        # Statistics
        print(f"    batch loss: {loss.item():0.3f}")
        _, y_label_ = torch.max(y_, 1)
        correct += (y_label_ == y).sum().item()
        running_loss += loss.item() * X.shape[0]
    
    print(f"  Train Loss: {running_loss / len(train_dl.dataset)}")
    loss_train = running_loss / len(train_dl.dataset)
    loss_graph1.append(loss_train)
    print(f"  Train Acc:  {correct / len(train_dl.dataset)}")

plt.plot(loss_graph1)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

# Testing
for epoch in range(1):
    print(f"Epoch {epoch}/{epoch}")
    
    # Eval
    model.eval()
    
    running_loss, correct = 0.0, 0
    with torch.no_grad():
        for X, y in val_dl:
            X, y = X.to(device), y.to(device)            
                               
            y_ = model(X)
        
            # Statistics
            _, y_label_ = torch.max(y_, 1)
            correct += (y_label_ == y).sum().item()
            loss = criterion(y_, y)
            running_loss += loss.item() * X.shape[0]
    
    print(f"  Valid Loss: {running_loss / len(val_dl.dataset)}")
    print(f"  Valid Acc:  {correct / len(val_dl.dataset)}")
    loss_test = running_loss / len(val_dl.dataset)
    loss_graph2.append(loss_test)
    print()

plt.plot(loss_graph2)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

def imshow(img):
  img = img / 2 + 0.5     # unnormalize
  npimg = img.numpy() # converts image into numpy
  plt.imshow(np.transpose(npimg, (1, 2, 0)))
  plt.show()

def im_convert(tensor):
  image = tensor.cpu().clone().numpy()
  image = image.transpose(1, 2, 0)
  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))
  image = image.clip(0, 1)
  return image

# Display Result
dataiter = iter(val_dl)
 
images, labels = dataiter.next()
 
images = images.to(device)
 
labels = labels.to(device)
 
output = model(images)
 
_, preds = torch.max(output, 1)
 
fig = plt.figure(figsize=(30, 5))
 
for idx in np.arange(20):
 
  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
 
  plt.imshow(im_convert(images[idx]))
 
  ax.set_title("{} ({})".format(str(classes[preds[idx].item()]), str(classes[labels[idx].item()])), color=("green" if preds[idx]==labels[idx] else "red"))

